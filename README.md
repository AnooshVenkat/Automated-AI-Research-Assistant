# Serverless AI Research Agent

This project implements a fully serverless, autonomous AI agent on AWS. The agent can take a research topic, browse the web for information, synthesize its findings into a coherent report, and save the result to cloud storage.

The entire architecture is designed to be cost-effective, running almost entirely within the AWS Free Tier for personal and development use. It serves as a powerful starter template for building more complex agentic AI workflows on a scalable, serverless backend.

## Core Technologies

-   **Agent Framework: [LangChain](https://www.langchain.com/)**
    -   Used to structure the agent, its tools, and the reasoning loops that connect the LLM to its capabilities.
-   **LLM: Google Gemini 1.5 Flash**
    -   The "brain" of the agent, responsible for understanding the research topic, processing information, and writing the final report.
-   **Compute: AWS Lambda**
    -   Hosts the Python code for the agent, running it in a serverless environment that only executes when triggered.
-   **Storage: AWS S3**
    -   Provides durable, long-term storage for the final research reports generated by the agent.
-   **Database: AWS DynamoDB**
    -   A NoSQL database used to log a history of every research task, including its ID, status, and a link to the report in S3.
-   **API: AWS API Gateway**
    -   Creates a public, secure HTTP endpoint that acts as the front door for the service, triggering the Lambda function on incoming requests.
-   **Web Search: SerpApi**
    -   A third-party service that provides the agent with a tool to perform real-time Google searches and get structured results.

## High-Level Setup

1.  **AWS Configuration:** Set up an S3 bucket to store reports and a DynamoDB table to log tasks.
2.  **IAM Role:** Create an IAM Role for the Lambda function with permissions to access S3, DynamoDB, and CloudWatch Logs.
3.  **Dependencies:** Package the Python dependencies (`langchain`, `boto3`, etc.) using Docker to ensure compatibility with the Amazon Linux runtime.
4.  **Lambda Deployment:** Create the Lambda function, upload the packaged code, and configure the necessary environment variables.
5.  **API Gateway Trigger:** Connect an API Gateway endpoint to the Lambda function to make it accessible via the web.

## Configuration

The Lambda function requires the following environment variables to be set in its configuration:

-   `GOOGLE_API_KEY`: Your API key for the Google AI Platform (for Gemini).
-   `SERPAPI_API_KEY`: Your API key from SerpApi for the web search tool.
-   `S3_BUCKET_NAME`: The name of the S3 bucket you created for storing reports.
-   `DYNAMODB_TABLE_NAME`: The name of the DynamoDB table you created for logging tasks.

## How to Use

To run the agent, send an `HTTPS POST` request to the API Gateway endpoint provided after deployment.

**Endpoint:** `https://<your-api-id>.execute-api.<region>.amazonaws.com/default/LangChainResearchAgent`

**Method:** `POST`

**Headers:**
```json
{
  "Content-Type": "application/json"
}
```

**Body:**
```json
{
  "topic": "the impact of quantum computing on cryptography"
}
```

**Success Response (200 OK):**
A successful request will trigger the agent and return a JSON object with details of the task.
```json
{
    "message": "Research task completed successfully!",
    "task_id": "a1b2c3d4-e5f6-7890-1234-567890abcdef",
    "s3_bucket": "my-ai-research-reports-12345",
    "s3_key": "reports/a1b2c3d4-e5f6-7890-1234-567890abcdef.txt"
}
```
You can then find the final report in the specified S3 bucket and the task log in the DynamoDB table.
